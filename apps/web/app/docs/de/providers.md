# Anbieter

izan.io unterstuetzt ueber **17 LLM-Anbieter** und bietet damit eine der umfangreichsten Integrationen fuer KI-Modelle in einer einzigen Plattform. Sie koennen zwischen Anbietern und Modellen frei wechseln, ohne die Oberflaeche zu verlassen.

## Unterstuetzte Anbieter

- **OpenAI** -- GPT-4o, GPT-5, o1, o3, o4 und weitere
- **Anthropic** -- Claude Opus, Sonnet, Haiku
- **Google** -- Gemini Pro, Flash, Ultra
- **Groq** -- schnelle Inferenz mit Open-Source-Modellen
- **Cerebras** -- extrem schnelle Inferenz
- **Cohere** -- Command R und Command R+
- **Together AI** -- Open-Source-Modelle in der Cloud
- **DeepSeek** -- DeepSeek V3, R1 und weitere
- **Mistral** -- Mistral Large, Medium, Small
- **xAI** -- Grok-Modelle
- **Fireworks** -- optimierte Open-Source-Modelle
- **Ollama** -- lokale Ausfuehrung auf Ihrem eigenen Rechner
- Und weitere Anbieter, die laufend ergaenzt werden

## Kostenlose Optionen

Sie muessen nicht bezahlen, um izan.io zu nutzen. Mehrere Anbieter bieten grosszuegige kostenlose Kontingente:

- **Google AI Studio** -- bis zu 250 Anfragen pro Tag ohne Kosten
- **Groq** -- kostenloses Kontingent fuer schnelle Inferenz
- **Cerebras** -- bis zu 1 Million Tokens pro Tag kostenlos
- **Ollama** -- vollstaendig kostenlos, da die Modelle lokal auf Ihrer Hardware laufen

## Einrichtung

1. Oeffnen Sie die **Einstellungen** ueber das Zahnrad-Symbol.
2. Suchen Sie den gewuenschten **Anbieter** in der Liste.
3. Geben Sie Ihren **API-Schluessel** ein (wird nur lokal gespeichert).
4. Waehlen Sie ein **Modell** aus der Modellliste des Anbieters.

## Modellfaehigkeiten

Nicht alle Modelle bieten dieselben Funktionen. izan.io kennzeichnet die Faehigkeiten jedes Modells:

- **Tool-Unterstuetzung** -- das Modell kann MCP-Tools und Makros aufrufen
- **Vision-Unterstuetzung** -- das Modell kann Bilder analysieren
- **Reasoning** -- das Modell verfuegt ueber erweiterte Denkfaehigkeiten (z. B. Chain-of-Thought)

## Flexibler Einsatz

Jedes Modell kann mit **jedem Agenten** kombiniert werden. Sie koennen beispielsweise den Domain-Experten mit einem guenstigen Modell fuer einfache Abfragen nutzen und fuer anspruchsvolle Aufgaben auf ein leistungsfaehigeres Modell wechseln -- alles innerhalb derselben Oberflaeche.
